{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.8' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Filter Paraphrase Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pair = pd.read_csv('../data/output/train_gen_pair_sampled_eval.txt', sep='\\t')\n",
    "train20k_pair = pd.read_csv('../data/output/train_gen_pair_20k_eval.txt', sep='\\t')\n",
    "trainfull_pair = pd.read_csv('../data/output/train_gen_pair_full_2_eval.txt', sep='\\t')\n",
    "dev_pair = pd.read_csv('../data/output/val_gen_pair_eval.txt', sep='\\t')\n",
    "test_pair = pd.read_csv('../data/output/test_gen_pair_eval.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pair_fil = train_pair[(~train_pair.gen.isna()) & \\\n",
    "                            (train_pair['preds'] == 0) & \\\n",
    "                            (train_pair.sem_similarity > 0.25)]\n",
    "train20k_pair_fil = train20k_pair[(~train20k_pair.gen.isna()) & \\\n",
    "                                  (train20k_pair['preds'] == 0) & \\\n",
    "                                  (train20k_pair.sem_similarity > 0.25)]\n",
    "trainfull_pair_fil = trainfull_pair[(~trainfull_pair.gen.isna()) & \\\n",
    "                                    (trainfull_pair['preds'] == 0) & \\\n",
    "                                    (trainfull_pair.sem_similarity > 0.25)]\n",
    "dev_pair_fil = dev_pair[(~dev_pair.gen.isna()) & (dev_pair['preds'] == 0)]\n",
    "test_pair_fil = test_pair[(~test_pair.gen.isna()) & (test_pair['preds'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4690, 8209, 11631)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pair_fil), len(train20k_pair_fil), len(trainfull_pair_fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.7/site-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "train_pair_fil.rename(columns={'ori': 'source'}, inplace=True)\n",
    "train20k_pair_fil.rename(columns={'ori': 'source'}, inplace=True)\n",
    "trainfull_pair_fil.rename(columns={'ori': 'source'}, inplace=True)\n",
    "dev_pair_fil.rename(columns={'ori': 'source'}, inplace=True)\n",
    "test_pair_fil.rename(columns={'ori': 'source'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pair_fil = train_pair_fil[['source', 'gen']]\n",
    "train20k_pair_fil = train20k_pair_fil[['source', 'gen']]\n",
    "trainfull_pair_fil = trainfull_pair_fil[['source', 'gen']]\n",
    "dev_pair_fil = dev_pair_fil[['source', 'gen']]\n",
    "test_pair_fil = test_pair_fil[['source', 'gen']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# train_pair_fil['gen'] = train_pair_fil.gen.apply(lambda x: [x])\n",
    "# train20k_pair_fil['gen'] = train20k_pair_fil.gen.apply(lambda x: [x])\n",
    "dev_pair_fil['gen'] = dev_pair_fil.gen.apply(lambda x: [x])\n",
    "test_pair_fil['gen'] = test_pair_fil.gen.apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Backtranslation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reference(row):\n",
    "    refs = [row['gen']]\n",
    "    if not pd.isnull(row['gen_ru']):\n",
    "        refs.append(row['gen_ru'])\n",
    "    if not pd.isnull(row['gen_es']):\n",
    "        refs.append(row['gen_es'])\n",
    "        \n",
    "    return str(refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esen_train_sel.txt 9489\n",
      "ruen_train_sel.txt 13854\n",
      "fren_train_sel.txt 14181\n"
     ]
    }
   ],
   "source": [
    "# load train data\n",
    "import os\n",
    "\n",
    "train_bt = None\n",
    "for path in os.listdir('../../backtranslate/data/'):\n",
    "    if 'train_sel' in path:\n",
    "        if train_bt is None:\n",
    "            train_bt = pd.read_csv(f'../../backtranslate/data/{path}', sep='\\t', index_col=0)\n",
    "        else:\n",
    "            train_bt = pd.concat([train_bt,\n",
    "                                 pd.read_csv(f'../../backtranslate/data/{path}', sep='\\t', index_col=0)])\n",
    "        \n",
    "        print(path, len(pd.read_csv(f'../../backtranslate/data/{path}', sep='\\t', index_col=0)))\n",
    "\n",
    "# train_bt.rename(columns={'backtranslate': 'gen'}, inplace=True)\n",
    "train_bt = train_bt[['source', 'gen']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>gen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just another vicious and trashy antitrump , pr...</td>\n",
       "      <td>Just another vicious and shameless anti-tromp,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>if we were not dumb lambs , why is it that the...</td>\n",
       "      <td>If we were not mute lambs, why is there an epi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>all this war talk goin on like why are we fuck...</td>\n",
       "      <td>All this war talk, why are we getting out of h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>but with a man , off with his head !</td>\n",
       "      <td>But with a man, out with his head!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>im willing to bet he flew the koop like many b...</td>\n",
       "      <td>I'm willing to bet he flew like a lot of black...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135353</th>\n",
       "      <td>butt butt butt butt butt butt butt butt butt b...</td>\n",
       "      <td>Butt Butt Butt Butt Butt Butt Butt Butt Butt B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135364</th>\n",
       "      <td>but id vote for someone i dont trust , before ...</td>\n",
       "      <td>But id vote for someone I don't trust, before ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135370</th>\n",
       "      <td>mental midgets think that the chain saw is the...</td>\n",
       "      <td>Dwarfs believe that chain saws are the only re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135374</th>\n",
       "      <td>im no supporter of drumpf either , but i love ...</td>\n",
       "      <td>I don't like the drummer's support either, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135377</th>\n",
       "      <td>it helps me know what cretins religious folks ...</td>\n",
       "      <td>It helps me to know what the religious of Cret...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37524 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   source  \\\n",
       "1       just another vicious and trashy antitrump , pr...   \n",
       "39      if we were not dumb lambs , why is it that the...   \n",
       "81      all this war talk goin on like why are we fuck...   \n",
       "94                   but with a man , off with his head !   \n",
       "97      im willing to bet he flew the koop like many b...   \n",
       "...                                                   ...   \n",
       "135353  butt butt butt butt butt butt butt butt butt b...   \n",
       "135364  but id vote for someone i dont trust , before ...   \n",
       "135370  mental midgets think that the chain saw is the...   \n",
       "135374  im no supporter of drumpf either , but i love ...   \n",
       "135377  it helps me know what cretins religious folks ...   \n",
       "\n",
       "                                                      gen  \n",
       "1       Just another vicious and shameless anti-tromp,...  \n",
       "39      If we were not mute lambs, why is there an epi...  \n",
       "81      All this war talk, why are we getting out of h...  \n",
       "94                     But with a man, out with his head!  \n",
       "97      I'm willing to bet he flew like a lot of black...  \n",
       "...                                                   ...  \n",
       "135353  Butt Butt Butt Butt Butt Butt Butt Butt Butt B...  \n",
       "135364  But id vote for someone I don't trust, before ...  \n",
       "135370  Dwarfs believe that chain saws are the only re...  \n",
       "135374  I don't like the drummer's support either, but...  \n",
       "135377  It helps me to know what the religious of Cret...  \n",
       "\n",
       "[37524 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with validation data\n",
    "dev_fr = pd.read_csv('../../backtranslate/data/fren_valid_sel.txt', sep='\\t', index_col=0)[['source', 'gen']]\n",
    "dev_ru = pd.read_csv('../../backtranslate/data/ruen_valid_sel.txt', sep='\\t', index_col=0)[['source', 'gen']]\n",
    "dev_es = pd.read_csv('../../backtranslate/data/esen_valid_sel.txt', sep='\\t', index_col=0)[['source', 'gen']]\n",
    "\n",
    "dev_frru = dev_fr.join(dev_ru, how='left', rsuffix='_ru')\n",
    "dev_frrues = dev_frru.join(dev_es, how='left', rsuffix='_es')\n",
    "\n",
    "dev_frrues['gen'] = dev_frrues.apply(make_reference, axis=1)\n",
    "dev_frrues = dev_frrues[['source', 'gen']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(762, 787, 506)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_fr), len(dev_ru), len(dev_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ru_left = dev_ru.loc[[i for i in dev_ru.index if i not in dev_fr.index]]\n",
    "dev_es_left = dev_es.loc[[i for i in dev_es.index if i not in dev_fr.index]]\n",
    "\n",
    "dev_ru_left['gen'] = dev_ru_left['gen'].apply(lambda x: [x])\n",
    "dev_es_left['gen'] = dev_es_left['gen'].apply(lambda x: [x])\n",
    "\n",
    "dev_bt = pd.concat([dev_frrues, dev_ru_left, dev_es_left])\n",
    "# dev_bt.rename(columns={'backtranslate': 'gen'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with test data\n",
    "test_fr = pd.read_csv('../../backtranslate/data/fren_test_sel.txt', sep='\\t', index_col=0)[['source', 'gen']]\n",
    "test_ru = pd.read_csv('../../backtranslate/data/ruen_test_sel.txt', sep='\\t', index_col=0)[['source', 'gen']]\n",
    "test_es = pd.read_csv('../../backtranslate/data/esen_test_sel.txt', sep='\\t', index_col=0)[['source', 'gen']]\n",
    "\n",
    "test_frru = test_fr.join(test_ru, how='left', rsuffix='_ru')\n",
    "test_frrues = test_frru.join(test_es, how='left', rsuffix='_es')\n",
    "\n",
    "test_frrues['gen'] = test_frrues.apply(make_reference, axis=1)\n",
    "test_frrues = test_frrues[['source', 'gen']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681, 551, 300)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_fr), len(test_ru), len(test_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ru_left = test_ru.loc[[i for i in test_ru.index if i not in test_fr.index]]\n",
    "test_es_left = test_es.loc[[i for i in test_es.index if i not in test_fr.index]]\n",
    "\n",
    "test_ru_left['gen'] = test_ru_left['gen'].apply(lambda x: [x])\n",
    "test_es_left['gen'] = test_es_left['gen'].apply(lambda x: [x])\n",
    "\n",
    "test_bt = pd.concat([test_frrues, test_ru_left, test_es_left])\n",
    "# test_bt.rename(columns={'backtranslate': 'gen'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = pd.concat([train_pair_fil, train_bt])\n",
    "train20k_all = pd.concat([train20k_pair_fil, train_bt])\n",
    "trainfull_all = pd.concat([trainfull_pair_fil, train_bt])\n",
    "dev_all = pd.concat([dev_pair_fil, dev_bt])\n",
    "test_all = pd.concat([test_pair_fil, test_bt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42214, 45733, 49155)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_all), len(train20k_all), len(trainfull_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all.to_csv('../../parallel-detox/data/train_pair_all.txt', sep='\\t', index=False, header=True)\n",
    "train20k_all.to_csv('../../parallel-detox/data/train20k_pair_all.txt', sep='\\t', index=False, header=True)\n",
    "trainfull_all.to_csv('../../parallel-detox/data/trainfull_pair_all.txt', sep='\\t', index=False, header=True)\n",
    "dev_all.to_csv('../../parallel-detox/data/valid_pair_all.txt', sep='\\t', index=False, header=True)\n",
    "test_all.to_csv('../../parallel-detox/data/test_pair_all.txt', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pair_fil.to_csv('../../parallel-detox/data/train_gpt_pair.txt', sep='\\t', index=False, header=True)\n",
    "train20k_pair_fil.to_csv('../../parallel-detox/data/train20k_gpt_pair.txt', sep='\\t', index=False, header=True)\n",
    "trainfull_pair_fil.to_csv('../../parallel-detox/data/trainfull_gpt_pair.txt', sep='\\t', index=False, header=True)\n",
    "dev_pair_fil.to_csv('../../parallel-detox/data/valid_gpt_pair.txt', sep='\\t', index=False, header=True)\n",
    "test_pair_fil.to_csv('../../parallel-detox/data/test_gpt_pair.txt', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bt.to_csv('../data/parallel/train_bt_pair.txt', sep='\\t', index=False, header=True)\n",
    "dev_bt.to_csv('../data/parallel/valid_bt_pair.txt', sep='\\t', index=False, header=True)\n",
    "test_bt.to_csv('../data/parallel/test_bt_pair.txt', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: the ugly american reeks its political fear.\n",
      "neutral:  American odors are political fears. \n",
      "**********\n",
      "toxic: likely sex slaves or even worse.\n",
      "neutral:  Probably slaves or even worse. \n",
      "**********\n",
      "toxic: hmm stupid pills, loser.\n",
      "neutral:  I guess I lost pills, my friend. \n",
      "**********\n",
      "toxic: trump is playing to the bigoted idiots that liked hisyears of birther horse excrement.\n",
      "neutral:  -is playing to the bigoted fans that loved his years of birther horse manure. \n",
      "**********\n",
      "toxic: juniors and his party are a disgrace.\n",
      "neutral:  Junior and his party are not a shame. \n",
      "**********\n",
      "toxic: comparing all this to the russian hacking ( whatever that means ) is obvious in its sheer stupidity.\n",
      "neutral:  Comparison with the Russian hacking is obvious in its absurdity. \n",
      "**********\n",
      "toxic: for the media forget the crap, and report facts from both sides\n",
      "neutral:  Forget the facts, and the media report from both sides. \n",
      "**********\n",
      "toxic: it only makes our mentally ill president feel good.\n",
      "neutral:  It only makes our president happy. \n",
      "**********\n",
      "toxic: every indication is that clintons partners were willing participants, unlike grab em by the pussy trump.\n",
      "neutral:  Every indication is that the clintons were willing partners, whereas the croupion reached its goal. \n",
      "**********\n",
      "toxic: hypocrisy as spoken in your own words :.\n",
      "neutral:  Hypocrisy as spoken in your own words . \n",
      "**********\n",
      "toxic: criminals like hillary clinton and obama to start with!\n",
      "neutral:  Bad guys like Hillary Clinton and Obama start with! \n",
      "**********\n",
      "toxic: its just plain stupid to take kids that young into a wilderness setting.\n",
      "neutral:  It's just plain wrong to take kids in a wild place. \n",
      "**********\n",
      "toxic: our city council is a joke, they let these fools run wild in the city no ankle bracelet or anything.\n",
      "neutral:  Our city council is a joke, they let these people come to town without any wristbands or anything. \n",
      "**********\n",
      "toxic: donald j. trump is calling for a complete and total shutdown of muslims entering the united states until our countrys representatives can figure out what the hell is going on.\n",
      "neutral:  Donald J. Trump calls for a complete and total shutdown of Muslims entering the United States until our representatives can figure out what's going on. \n",
      "**********\n",
      "toxic: where did this stupid busy body come from lol?\n",
      "neutral:  Where did this great body come from? \n",
      "**********\n",
      "toxic: the nra and the republicans they own are going straight to hell.\n",
      "neutral:  The Nazi and the Republicans' ownership are getting there. \n",
      "**********\n",
      "toxic: i never used the word bitches.\n",
      "neutral:  I never said that the hair. \n",
      "**********\n",
      "toxic: he was the most picked on pussy in high school and now he is a tough guy with a gun.\n",
      "neutral:  He was the most picked on in school and now he has a gun. \n",
      "**********\n",
      "toxic: after the meeting, secretary of state rex tillerson referred to trump as a moron.\n",
      "neutral:  After the meeting, secretary of state Rex Tillerson referred to the croupion as a monique. \n",
      "**********\n",
      "toxic: you guys going to do some docking and talk about the evil black man?\n",
      "neutral:  Guys, you're going to dock and talk about the black man? \n",
      "**********\n",
      "toxic: bernstein is a leftist fool, but an expert at malignant reporting.\n",
      "neutral:  Bernstein is a leftist trick, but an expert at malignant reports. \n",
      "**********\n",
      "toxic: in discussions at morning report the consensus among the medical staff was you get sued for being a jerk to patients and their families not for bad outcomes.\n",
      "neutral:  In the morning news the consensus among the medical staff was that you have to pay damages to patients and their families not to suffer bad outcomes. \n",
      "**********\n",
      "toxic: , oh ibbitson you idiot, it is still a party hack club,\n",
      "neutral:  , Oh Ibitson, it's still a hack club. \n",
      "**********\n",
      "toxic: id be afraid of some of that stupid rubbing off on me.\n",
      "neutral:  I'm afraid of rubbing on me. \n",
      "**********\n",
      "toxic: yet another example of disgraceful, corrupt scofflaws running eugenes bureaucracy.\n",
      "neutral:  Yet another example of dishonesty, corruption, of corruption of the eugene bureaucracy. \n",
      "**********\n",
      "toxic: yep, theyre using the homosexual hillarys guide to debate : everyone with whom you disagree, call them a nazi\n",
      "neutral:  Yup, they're using the Gay Hilary's guide to debate everyone with whom you disagree, call them Nazis. \n",
      "**********\n",
      "toxic: so trump is going to kill us all with his environmental policies?\n",
      "neutral:  So the bonus will kill us all with the environmental policies? \n",
      "**********\n",
      "toxic: and your going to be on the other side illegitimis non carborundum you dirty foreigner.\n",
      "neutral:  and you're going to be on the other side illegitimis noncarborundum, you're a foreigner. \n",
      "**********\n",
      "toxic: a lot of silly words on a serious subject.\n",
      "neutral:  A lot of funny words on a serious subject. \n",
      "**********\n",
      "toxic: you idiot and harper lived prior to the election.\n",
      "neutral:  You lived before the election. \n",
      "**********\n",
      "toxic: play stupid games and win hollow point prizes.\n",
      "neutral:  Play bad games and win the hollow points. \n",
      "**********\n",
      "toxic: gm is crap although not as bad as chrysler fiat.\n",
      "neutral:  Gm's fine, but not as bad as Chrysler. \n",
      "**********\n",
      "toxic: fox clowns only deal in inuendo.\n",
      "neutral:  Clowns only do inuendo. \n",
      "**********\n",
      "toxic: the players who have served before and fuck all the players who help their communities and other charities.\n",
      "neutral:  The players who have served before and have screwed all the players who help the communities and other charities. \n",
      "**********\n",
      "toxic: they are willing to give up that all for one, one for all, stick to the party line garbage they live by in order to denounce trump.\n",
      "neutral:  They're willing to give up that one for all, one for all, stick to the party line for all of it, so they denounce it. \n",
      "**********\n",
      "toxic: like you say, your cousin is a dimwit must run in the family.\n",
      "neutral:  Like you say, my cousin is a mute must run in the family. \n",
      "**********\n",
      "toxic: your diatribe is as stupid as it gets.\n",
      "neutral:  Your diatribe is as serious as it is. \n",
      "**********\n",
      "toxic: the dems do this garbage too.\n",
      "neutral:  Dems do this waste too. \n",
      "**********\n",
      "toxic: your hatred of the police is nonsensical and just plain stupid.\n",
      "neutral:  Your hatred of the police is incomprehensible and just plain senseless. \n",
      "**********\n",
      "toxic: gms surge just shows there are lots of dumb shoppers in canada.\n",
      "neutral:  Gms surges just shows that there are lots of empty shopping in Canada. \n",
      "**********\n",
      "toxic: if, in fact, the russkis did hack the emails, they did america a huge favor by outing the corruption and graft imbedded in the establishment donkey party.\n",
      "neutral:  If, in fact, the Russians hacked the emails, they did America a huge favor by exposing corruption and graft embedded in the establishment donkey party. \n",
      "**********\n",
      "toxic: please share with the rest of us haplessly ignorant masses.\n",
      "neutral:  Please share with us, without knowing what we're missing. \n",
      "**********\n",
      "toxic: what a doofus he was.\n",
      "neutral:  What a clumsy he was. \n",
      "**********\n",
      "toxic: quite likelybecause were dealing with human beings heresome gays are sexual predators.\n",
      "neutral:  Probably because the people who dealt with the people who were doing the sexual things were attracted to people who were doing the same thing. \n",
      "**********\n",
      "toxic: he pled guilty you fucking moron!\n",
      "neutral:  ! You've done it! \n",
      "**********\n",
      "toxic: pathetic display of poor governance beliefs of both quebec and ottawa politicians.\n",
      "neutral:  A sad display of poor decisions of both the Quebec and the Ontario politicians. \n",
      "**********\n",
      "toxic: whether or not i am happy about the bundy militia idiot gang getting prison raped will not have any effect on its occurrence.\n",
      "neutral:  Whether or not I am happy about the gang that gets prison raped will not have any effect on its occurrence. \n",
      "**********\n",
      "toxic: he has to be a terrorist!.\n",
      "neutral:  It has to be a terrorist! \n",
      "**********\n",
      "toxic: the chump train is heading for certain derailment and the chumpsters are stuck on it because they have st for brains.\n",
      "neutral:  The train that went through a gap on the chute is headed to a certain disaster and the trains stuck on it because they have been unable to see. \n",
      "**********\n",
      "toxic: what the hell do you think you are talking about?\n",
      "neutral:  What do you think you're talking about? \n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "for _, i in dev_pair_fil.head(50).iterrows():\n",
    "    print(f'toxic: {i[\"ori\"]}')\n",
    "    print(f'neutral: {i[\"gen\"]}')\n",
    "    print('*' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
