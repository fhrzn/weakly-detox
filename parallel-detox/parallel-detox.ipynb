{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.8' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW \n",
    "from transformers import get_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import DatasetDict, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:3' if torch.cuda.is_available() else 'cpu'\n",
    "MODEL_CKPT = 'facebook/bart-base'\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CKPT)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_CKPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/parallel/train_gpt_pair.txt', sep='\\t')\n",
    "dev = pd.read_csv('../data/parallel/valid_gpt_pair.txt', sep='\\t')\n",
    "test = pd.read_csv('../data/parallel/test_gpt_pair.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'gen'],\n",
       "        num_rows: 4690\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['source', 'gen'],\n",
       "        num_rows: 2546\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source', 'gen'],\n",
       "        num_rows: 3988\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weak_parallel = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train),\n",
    "    'dev': Dataset.from_pandas(dev),\n",
    "    'test': Dataset.from_pandas(test)\n",
    "})\n",
    "\n",
    "try:\n",
    "    weak_parallel = weak_parallel.remove_columns(['__index_level_0__'])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "weak_parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def clean_beginning_symb(text):\n",
    "    return re.sub(r'^[^A-z0-9\\\"\\']+', '', text)\n",
    "\n",
    "def tokenize(data, mode='train'):\n",
    "    source = [clean_beginning_symb(i.strip()) for i in data['source']]\n",
    "    if mode == 'infer':\n",
    "        pass\n",
    "    elif mode == 'train':\n",
    "        gen = [clean_beginning_symb(i.strip()) for i in data['gen']]\n",
    "    else:\n",
    "        gen = []\n",
    "        first_gen = []\n",
    "        for sgen in data['gen']:\n",
    "            try:\n",
    "                sgen = ast.literal_eval(sgen)\n",
    "            except:\n",
    "                print(sgen)\n",
    "            for i, igen in enumerate(sgen):\n",
    "                if i == 0:\n",
    "                    first_gen.append(igen)\n",
    "                gen.append(clean_beginning_symb(igen.strip()))\n",
    "                \n",
    "    if mode == 'infer':\n",
    "        tokenized = tokenizer(source,\n",
    "                             max_length=128,\n",
    "                             truncation=True,\n",
    "                             padding='max_length')\n",
    "    else:\n",
    "        tokenized = tokenizer(source,\n",
    "                             max_length=128,\n",
    "                             truncation=True,\n",
    "                             text_target=gen if mode == 'train' else first_gen,\n",
    "                             padding='max_length')\n",
    "    \n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19e5ea78e8248198db058681c681bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64e9b511e0c445a8561d616de835b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9128f16be094b7e972130e13f96dec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weak_parallel_train = weak_parallel['train'].map(tokenize, batched=True, fn_kwargs={'mode': 'train'})\n",
    "weak_parallel_dev = weak_parallel['dev'].map(tokenize, batched=True, fn_kwargs={'mode': 'dev'})\n",
    "weak_parallel_test = weak_parallel['test'].map(tokenize, batched=True, fn_kwargs={'mode': 'test'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_parallel_train.set_format('torch')\n",
    "weak_parallel_dev.set_format('torch')\n",
    "weak_parallel_test.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(weak_parallel_train,\n",
    "                         batch_size=BATCH_SIZE, shuffle=True)\n",
    "devloader = DataLoader(weak_parallel_dev,\n",
    "                       batch_size=BATCH_SIZE, shuffle=False)\n",
    "testloader = DataLoader(weak_parallel_test,\n",
    "                        batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "\n",
    "num_epochs = 10\n",
    "num_train_steps = num_epochs * len(trainloader)\n",
    "scheduler = get_scheduler('linear',\n",
    "                         optimizer=optimizer,\n",
    "                         num_warmup_steps=0,\n",
    "                         num_training_steps=num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a7c543dfd2456ab7af53904fa795ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/740 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb155aa57364b03b51855f7c4c62bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1\n",
      "TLoss: 5.463384261002412 | VLoss: 1.7136989533901215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284a99d56e9444ae8c6bfc023d8d2e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2\n",
      "TLoss: 0.7553163460783057 | VLoss: 0.3903397299349308\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105f42ac52fb4df6b336b2f7a55fb80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 3\n",
      "TLoss: 0.29320731718797943 | VLoss: 0.250467798858881\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca14a0d187c4da786e78322d33619ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 4\n",
      "TLoss: 0.23213816474418383 | VLoss: 0.2219876952469349\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d2c4333f0046afaba400f7995bfb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 5\n",
      "TLoss: 0.2065765585851025 | VLoss: 0.19642027728259565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0935c171136742f290ee48feade3590d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 6\n",
      "TLoss: 0.1907325183620324 | VLoss: 0.16942997612059116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33624795e5564da1ad295401e88b4995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 7\n",
      "TLoss: 0.18203413043473218 | VLoss: 0.12181725930422545\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b311157213410192054fa4500a454e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 8\n",
      "TLoss: 0.17585931275341962 | VLoss: 0.13671531565487385\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf90839c70b41ec89024a0d496dba3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 9\n",
      "TLoss: 0.17197800729725812 | VLoss: 0.1715612981468439\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9109d08067f49b2af2df439b1d21396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 10\n",
      "TLoss: 0.16977425704936724 | VLoss: 0.15310046672821045\n"
     ]
    }
   ],
   "source": [
    "tloss = []\n",
    "vloss = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "progressbar = tqdm(range(num_train_steps), desc='Training')\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    \n",
    "    tloss_ = 0\n",
    "    vloss_ = 0\n",
    "    model.train()\n",
    "\n",
    "    for batch in trainloader:\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items() if k in ['attention_mask', 'input_ids', 'labels']}\n",
    "        out = model(**batch)\n",
    "        \n",
    "        tloss_ += out.loss.item()\n",
    "        \n",
    "        out.loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progressbar.update(1)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for vbatch in tqdm(devloader, desc='Evaluation', leave=True):\n",
    "            batch = {k: v.to(DEVICE) for k, v in batch.items() if k in ['attention_mask', 'input_ids', 'labels']}\n",
    "            out = model(**batch)\n",
    "            \n",
    "            vloss_ += out.loss.item()\n",
    "            \n",
    "\n",
    "    tloss_ /= len(trainloader)\n",
    "    vloss_ /= len(devloader)\n",
    "    tloss.append(tloss_)\n",
    "    vloss.append(vloss_)\n",
    "    \n",
    "    if vloss_ < best_loss:\n",
    "        best_loss = vloss_\n",
    "        torch.save(model.state_dict(), './model/bart-parallel-gpt20k.pth')\n",
    "    \n",
    "    print('Epoch - {}'.format(e + 1))\n",
    "    print('TLoss: {} | VLoss: {}'.format(tloss_, vloss_))\n",
    "    \n",
    "progressbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./model/bart-parallel-gpt20k.pth', map_location=DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1c73c30df4444795a6a8bf157cabde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3679695763285198\n"
     ]
    }
   ],
   "source": [
    "testloss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tbatch in tqdm(testloader, desc='Testing'):\n",
    "        tbatch = {k: v.to(DEVICE) for k, v in tbatch.items() if k in ['attention_mask', 'input_ids', 'labels']}\n",
    "        out = model(**tbatch)\n",
    "        testloss += out.loss.item()\n",
    "        \n",
    "testloss /= len(testloader)\n",
    "print('Test Loss: {}'.format(testloss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694ae8e786f3413fb8f01f727e3cda22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bart_out = []\n",
    "\n",
    "for tbatch in tqdm(testloader, desc='Inference'):\n",
    "    out = model.generate(input_ids=tbatch['input_ids'].to(DEVICE),\n",
    "                        attention_mask=tbatch['attention_mask'].to(DEVICE),\n",
    "                        num_beams=8,\n",
    "                        do_sample=True,\n",
    "                        min_length=1,\n",
    "                        max_length=128)\n",
    "    bart_out.extend(tokenizer.batch_decode(out, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['gen.bart'] = bart_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>gen</th>\n",
       "      <th>gen.bart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the stupid advising the stupid.</td>\n",
       "      <td>[' The advice of the advice. ']</td>\n",
       "      <td>The advice advising the foolish.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what planet of stupid are you on?</td>\n",
       "      <td>[' What planet do you live on? ']</td>\n",
       "      <td>What planet are you on?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this guy needs to have you are a stupid idiot!</td>\n",
       "      <td>[\" This guy's got to be a hard thing! \"]</td>\n",
       "      <td>This guy needs to have you!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>youre really a stupid asshole.</td>\n",
       "      <td>[\" You're really an awkward one. \"]</td>\n",
       "      <td>You're really a funny guy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this stupid nazi woman is a fucking bitch.</td>\n",
       "      <td>[\" This woman's a little mad. \"]</td>\n",
       "      <td>This woman's a bitch.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           source  \\\n",
       "0                 the stupid advising the stupid.   \n",
       "1               what planet of stupid are you on?   \n",
       "2  this guy needs to have you are a stupid idiot!   \n",
       "3                  youre really a stupid asshole.   \n",
       "4      this stupid nazi woman is a fucking bitch.   \n",
       "\n",
       "                                        gen                          gen.bart  \n",
       "0           [' The advice of the advice. ']  The advice advising the foolish.  \n",
       "1         [' What planet do you live on? ']           What planet are you on?  \n",
       "2  [\" This guy's got to be a hard thing! \"]       This guy needs to have you!  \n",
       "3       [\" You're really an awkward one. \"]        You're really a funny guy.  \n",
       "4          [\" This woman's a little mad. \"]             This woman's a bitch.  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on Jigsaw Toxic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(DEVICE)\n",
    "model.load_state_dict(torch.load('./model/bart-parallel-gpt20k.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you are a fucking idiot .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>as stupid and arrogant as his boss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a stupid society does stupid things and votes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a president who is an idiot .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>colbert is a stupid moron and is a terrorist .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source\n",
       "0                          you are a fucking idiot .\n",
       "1                 as stupid and arrogant as his boss\n",
       "2  a stupid society does stupid things and votes ...\n",
       "3                      a president who is an idiot .\n",
       "4     colbert is a stupid moron and is a terrorist ."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttox = pd.read_csv('../data/seq2seq/test.tox', sep='\\t', names=['source'])\n",
    "ttox.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed84cdd9cfd2445497e75777eb302d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "infer_dataset = Dataset.from_pandas(ttox)\n",
    "infer_dataset_tokenized = infer_dataset.map(tokenize, batched=True, remove_columns=['source'], fn_kwargs={'mode': 'infer'})\n",
    "infer_dataset_tokenized.set_format('torch')\n",
    "\n",
    "infer_dataloader = DataLoader(infer_dataset_tokenized, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd5653f3ae044d9ac0f30fee943754b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bartdetox_out = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(infer_dataloader, desc='Inference'):\n",
    "        out = model.generate(input_ids=data['input_ids'].to(DEVICE),\n",
    "                            attention_mask=data['attention_mask'].to(DEVICE),\n",
    "                            num_beams=8,\n",
    "                            do_sample=True,\n",
    "                            min_length=1,\n",
    "                            max_length=128)\n",
    "\n",
    "        bartdetox_out.extend(tokenizer.batch_decode(out, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttox['gen'] = bartdetox_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttox[['source', 'gen']].to_csv('../data/parallel/output/bart_gpt20k.txt', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>gen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you are a fucking idiot .</td>\n",
       "      <td>You're a fool.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>as stupid and arrogant as his boss</td>\n",
       "      <td>As stupid and arrogant as his boss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a stupid society does stupid things and votes ...</td>\n",
       "      <td>A stupid society does things and votes for pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a president who is an idiot .</td>\n",
       "      <td>A president who is a joke.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>colbert is a stupid moron and is a terrorist .</td>\n",
       "      <td>Colbert is a mistake and is a terrorist.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0                          you are a fucking idiot .   \n",
       "1                 as stupid and arrogant as his boss   \n",
       "2  a stupid society does stupid things and votes ...   \n",
       "3                      a president who is an idiot .   \n",
       "4     colbert is a stupid moron and is a terrorist .   \n",
       "\n",
       "                                                 gen  \n",
       "0                                     You're a fool.  \n",
       "1                As stupid and arrogant as his boss.  \n",
       "2  A stupid society does things and votes for pol...  \n",
       "3                         A president who is a joke.  \n",
       "4           Colbert is a mistake and is a terrorist.  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttox.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Style Transfer Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at s-nlp/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "TOXIC_CKPT = 's-nlp/roberta_toxicity_classifier'\n",
    "toxic_tokenizer = AutoTokenizer.from_pretrained(TOXIC_CKPT)\n",
    "toxic_model = AutoModelForSequenceClassification.from_pretrained(TOXIC_CKPT)\n",
    "toxic_model = toxic_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(text, tokenizer, classifier):\n",
    "    tokenized = tokenizer(text,\n",
    "                         truncation=True,\n",
    "                         max_length=128,\n",
    "                         padding='max_length',\n",
    "                         return_tensors='pt')\n",
    "    tokenized = {k: v.to(DEVICE) for k, v in tokenized.items()}\n",
    "    with torch.no_grad():\n",
    "        out = classifier(**tokenized).logits\n",
    "    proba = torch.softmax(out, dim=1).squeeze()\n",
    "    label = torch.argmax(proba)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    del tokenized\n",
    "    \n",
    "    return {'normal_proba': proba[0].item(),\n",
    "            'toxic_proba': proba[1].item(),\n",
    "            'predicted_label': label.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425f50a909aa4aadab7d384930eef195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "STA Eval: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-f93e4600f031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msta_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bart'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoxic_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoxic_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msta_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mbleus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'bleu'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbleu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gen'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bleu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/evaluate/module.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtemp_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcompute_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_writer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--bleu/9e0985c1200e367cce45605ce0ecb5ede079894e0f24f54613fca08eeb8aff76/bleu.py\u001b[0m in \u001b[0;36m_compute\u001b[0;34m(self, predictions, references, tokenizer, max_order, smooth)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         score = compute_bleu(\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mreference_corpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation_corpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         )\n\u001b[1;32m    125\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mbleu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_length\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--bleu/9e0985c1200e367cce45605ce0ecb5ede079894e0f24f54613fca08eeb8aff76/nmt_bleu.py\u001b[0m in \u001b[0;36mcompute_bleu\u001b[0;34m(reference_corpus, translation_corpus, max_order, smooth)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mbp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mbp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mbleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeo_mean\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "bleu = evaluate.load('bleu')\n",
    "stas = []\n",
    "bleus = []\n",
    "\n",
    "for i, row in tqdm(ttox.iterrows(), desc='STA Eval'):\n",
    "    sta_score = predict_label(row['bart'], toxic_tokenizer, toxic_model)\n",
    "    stas.append(sta_score)\n",
    "    bleus.append({'bleu': bleu.compute(predictions=[row['gen'].lower()], references=[row['source'].lower()], max_order=4)['bleu']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttox_ = pd.concat([ttox, pd.DataFrame(stas), pd.DataFrame(bleus)], axis=1)\n",
    "ttox_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"STA: {accuracy_score(np.zeros(len(ttox_), dtype=int), ttox_['predicted_label'].to_numpy())}\")\n",
    "print(f\"BLEU: {ttox_['bleu'].mean() * 100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
