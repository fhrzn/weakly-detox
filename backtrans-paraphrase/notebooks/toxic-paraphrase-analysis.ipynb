{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.8' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CKPT = 'roberta-base'\n",
    "S_ROBERTA  = 's-nlp/roberta_toxicity_classifier'\n",
    "DEVICE = 'cuda:4' if torch.cuda.is_available else 'cpu'\n",
    "DEVICE2 = 'cuda:3' if torch.cuda.is_available else 'cpu'\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simple filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../data/paraphrase/output/train_gen_pair_sampled.txt', sep='\\t')\n",
    "dev = pd.read_csv('../../data/paraphrase/output/val_gen_pair.txt', sep='\\t')\n",
    "test = pd.read_csv('../../data/paraphrase/output/test_gen_pair.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train20k = pd.read_csv('../../data/paraphrase/output/train_gen_pair_20k.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['gen'] = train.gen.fillna('')\n",
    "dev['gen'] = dev.gen.fillna('')\n",
    "test['gen'] = test.gen.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train20k['gen'] = train20k.gen.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further cleaning\n",
    "train['ori'] = train['ori'].apply(lambda x: x.replace('toxic: ', '').strip())\n",
    "train['gen'] = train['gen'].apply(lambda x: x[:x.index('</s>')].replace('normal ', ''.strip()) \\\n",
    "                                   if '</s>' in x else x.replace('normal ', '').strip())\n",
    "\n",
    "dev['ori'] = dev['ori'].apply(lambda x: x.replace('toxic: ', '').strip())\n",
    "dev['gen'] = dev['gen'].apply(lambda x: x[:x.index('</s>')].replace('normal ', ''.strip()) \\\n",
    "                                   if '</s>' in x else x.replace('normal ', '').strip())\n",
    "\n",
    "test['ori'] = test['ori'].apply(lambda x: x.replace('toxic: ', '').strip())\n",
    "test['gen'] = test['gen'].apply(lambda x: x[:x.index('</s>')].replace('normal ', ''.strip()) \\\n",
    "                                   if '</s>' in x else x.replace('normal ', '').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train20k['ori'] = train20k['ori'].apply(lambda x: x.replace('toxic: ', '').strip())\n",
    "train20k['gen'] = train20k['gen'].apply(lambda x: x[:x.index('</s>')].replace('normal ', ''.strip()) \\\n",
    "                                   if '</s>' in x else x.replace('normal ', '').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['chr_count'] = train['gen'].apply(lambda x: len(x))\n",
    "dev['chr_count'] = dev['gen'].apply(lambda x: len(x))\n",
    "test['chr_count'] = test['gen'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train20k['chr_count'] = train20k['gen'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fil = train[train['chr_count'] > 10]\n",
    "dev_fil = dev[dev['chr_count'] > 10]\n",
    "test_fil = test[test['chr_count'] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generated</th>\n",
       "      <th>ori</th>\n",
       "      <th>gen</th>\n",
       "      <th>chr_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paraphrase: toxic:  mccain was too stupid to p...</td>\n",
       "      <td>mccain was too stupid to pick palin.</td>\n",
       "      <td>McCain was too stunned to pick Palin.</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paraphrase: toxic:  this is the dumbest argume...</td>\n",
       "      <td>this is the dumbest argument ive ever heard ag...</td>\n",
       "      <td>This is the dumbest argument I've ever heard ...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paraphrase: toxic:  that stupid movie with nic...</td>\n",
       "      <td>that stupid movie with nicholas cage really de...</td>\n",
       "      <td>Nicolas Cage's movie really demeaned their co...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paraphrase: toxic:  wankers, the lot of them. ...</td>\n",
       "      <td>wankers, the lot of them.</td>\n",
       "      <td>Wankers, the lot of them.</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paraphrase: toxic:  you lefties are such sheep...</td>\n",
       "      <td>you lefties are such sheepletons.</td>\n",
       "      <td>You lefty are so sheep, to which you belong.</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           generated  \\\n",
       "0  paraphrase: toxic:  mccain was too stupid to p...   \n",
       "1  paraphrase: toxic:  this is the dumbest argume...   \n",
       "2  paraphrase: toxic:  that stupid movie with nic...   \n",
       "3  paraphrase: toxic:  wankers, the lot of them. ...   \n",
       "4  paraphrase: toxic:  you lefties are such sheep...   \n",
       "\n",
       "                                                 ori  \\\n",
       "0               mccain was too stupid to pick palin.   \n",
       "1  this is the dumbest argument ive ever heard ag...   \n",
       "2  that stupid movie with nicholas cage really de...   \n",
       "3                          wankers, the lot of them.   \n",
       "4                  you lefties are such sheepletons.   \n",
       "\n",
       "                                                 gen  chr_count  \n",
       "0             McCain was too stunned to pick Palin.          39  \n",
       "1   This is the dumbest argument I've ever heard ...         67  \n",
       "2   Nicolas Cage's movie really demeaned their co...         58  \n",
       "3                         Wankers, the lot of them.          27  \n",
       "4      You lefty are so sheep, to which you belong.          46  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train20k_fil = train20k[train20k['chr_count'] > 10]\n",
    "train20k_fil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generated</th>\n",
       "      <th>ori</th>\n",
       "      <th>gen</th>\n",
       "      <th>chr_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paraphrase: toxic:  mccain was too stupid to p...</td>\n",
       "      <td>mccain was too stupid to pick palin.</td>\n",
       "      <td>McCain was too clever to pick Palin.</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paraphrase: toxic:  this is the dumbest argume...</td>\n",
       "      <td>this is the dumbest argument ive ever heard ag...</td>\n",
       "      <td>This is the strangest argument against gun con...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paraphrase: toxic:  that stupid movie with nic...</td>\n",
       "      <td>that stupid movie with nicholas cage really de...</td>\n",
       "      <td>Nicolas Cage really demeaned their contribution.</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paraphrase: toxic:  wankers, the lot of them. ...</td>\n",
       "      <td>wankers, the lot of them.</td>\n",
       "      <td>Drinkers, the lot of them.</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paraphrase: toxic:  you lefties are such sheep...</td>\n",
       "      <td>you lefties are such sheepletons.</td>\n",
       "      <td>You left-handed people are so very sheep.</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           generated  \\\n",
       "0  paraphrase: toxic:  mccain was too stupid to p...   \n",
       "1  paraphrase: toxic:  this is the dumbest argume...   \n",
       "2  paraphrase: toxic:  that stupid movie with nic...   \n",
       "3  paraphrase: toxic:  wankers, the lot of them. ...   \n",
       "4  paraphrase: toxic:  you lefties are such sheep...   \n",
       "\n",
       "                                                 ori  \\\n",
       "0               mccain was too stupid to pick palin.   \n",
       "1  this is the dumbest argument ive ever heard ag...   \n",
       "2  that stupid movie with nicholas cage really de...   \n",
       "3                          wankers, the lot of them.   \n",
       "4                  you lefties are such sheepletons.   \n",
       "\n",
       "                                                 gen  chr_count  \n",
       "0               McCain was too clever to pick Palin.         36  \n",
       "1  This is the strangest argument against gun con...         51  \n",
       "2   Nicolas Cage really demeaned their contribution.         48  \n",
       "3                         Drinkers, the lot of them.         26  \n",
       "4          You left-handed people are so very sheep.         41  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12000 entries, 0 to 11999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   generated  12000 non-null  object\n",
      " 1   ori        12000 non-null  object\n",
      " 2   gen        12000 non-null  object\n",
      " 3   chr_count  12000 non-null  int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 375.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11973 entries, 0 to 11999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   generated  11973 non-null  object\n",
      " 1   ori        11973 non-null  object\n",
      " 2   gen        11973 non-null  object\n",
      " 3   chr_count  11973 non-null  int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 467.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.info(), train_fil.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19965 entries, 0 to 19999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   generated  19965 non-null  object\n",
      " 1   ori        19965 non-null  object\n",
      " 2   gen        19965 non-null  object\n",
      " 3   chr_count  19965 non-null  int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 779.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train20k_fil.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train20k_fil[['generated', 'ori', 'gen']].to_csv('../../data/paraphrase/output/train_gen_pair_20k_.txt',\n",
    "                                                index=False, header=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['gen'],\n",
       "        num_rows: 11973\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['gen'],\n",
       "        num_rows: 6150\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['gen'],\n",
       "        num_rows: 9569\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxics = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train_fil[['gen']]),\n",
    "    'validation': Dataset.from_pandas(dev_fil[['gen']]),\n",
    "    'test': Dataset.from_pandas(test_fil[['gen']])\n",
    "})\n",
    "\n",
    "try:\n",
    "    toxics = toxics.remove_columns(['__index_level_0__'])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "toxics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "id2label = {0: 'Normal', 1: 'Toxic'}\n",
    "label2id = {'Normal': 0, 'Toxic': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at s-nlp/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CKPT)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_CKPT,\n",
    "                                                           num_labels=2,\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "sta_model = AutoModelForSequenceClassification.from_pretrained(S_ROBERTA,\n",
    "                                                               num_labels=2,\n",
    "                                                               id2label=id2label,\n",
    "                                                               label2id=label2id)\n",
    "sta_model = sta_model.to(DEVICE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = load_checkpoint('../model/ft-robertoxic-classifier.pth', model=model)\n",
    "model.load_state_dict(torch.load('../../classifier/model/ft-robertoxic-classifier.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(batch):\n",
    "    try:\n",
    "        comment = batch['gen.2']\n",
    "    except:\n",
    "        comment = batch['gen']\n",
    "    \n",
    "    tokenized = tokenizer(\n",
    "        comment,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        padding='max_length'\n",
    "    )\n",
    "\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5525de32dcb34a149a269771e5c154e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7a5916b1284559a66599e35433daba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36f49dc4de44a19921d817ebc104340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['gen', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 11973\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['gen', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 6150\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['gen', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 9569\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxics_tokenized = toxics.map(tokenize_data, batched=True)\n",
    "toxics_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxics_tokenized.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(toxics_tokenized['train'], shuffle=False, batch_size=BATCH_SIZE)\n",
    "devloader = DataLoader(toxics_tokenized['validation'], shuffle=False, batch_size=BATCH_SIZE)\n",
    "testloader = DataLoader(toxics_tokenized['test'], shuffle=False, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b570975e690746b7a8b9dbe2b6861adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainpreds = []\n",
    "train_tox_proba = []\n",
    "train_norm_proba = []\n",
    "\n",
    "stapreds = []\n",
    "sta_tox_proba = []\n",
    "sta_norm_proba = []\n",
    "\n",
    "for batch in tqdm(trainloader):\n",
    "    # self trained model\n",
    "    batch = {k: v.to(DEVICE) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
    "    out = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "        \n",
    "    logits = out.logits.squeeze().detach().cpu()\n",
    "    probs = torch.sigmoid(logits)    \n",
    "    preds = torch.argmax(probs, dim=1).numpy()\n",
    "    \n",
    "    train_norm_proba.extend(probs[:, 0].tolist())\n",
    "    train_tox_proba.extend(probs[:, 1].tolist())\n",
    "    trainpreds.extend(preds.tolist())\n",
    "    \n",
    "    # sta model\n",
    "    batch = {k: v.to(DEVICE2) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
    "    out2 = sta_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "\n",
    "    logits = out2.logits.squeeze().detach().cpu()\n",
    "    probs = torch.sigmoid(logits)    \n",
    "    preds = torch.argmax(probs, dim=1).numpy()\n",
    "    \n",
    "    sta_norm_proba.extend(probs[:, 0].tolist())\n",
    "    sta_tox_proba.extend(probs[:, 1].tolist())\n",
    "    stapreds.extend(preds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef20e5d877044f11a5218d8761e93f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/193 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "devpreds = []\n",
    "dev_tox_proba = []\n",
    "dev_norm_proba = []\n",
    "\n",
    "dev_stapreds = []\n",
    "dev_sta_tox_proba = []\n",
    "dev_sta_norm_proba = []\n",
    "\n",
    "for batch in tqdm(devloader):\n",
    "    # self trained model\n",
    "    batch = {k: v.to(DEVICE) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
    "    out = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "        \n",
    "    logits = out.logits.squeeze().detach().cpu()\n",
    "    probs = torch.sigmoid(logits)    \n",
    "    preds = torch.argmax(probs, dim=1).numpy()\n",
    "    \n",
    "    dev_norm_proba.extend(probs[:, 0].tolist())\n",
    "    dev_tox_proba.extend(probs[:, 1].tolist())\n",
    "    devpreds.extend(preds.tolist())\n",
    "    \n",
    "    # sta model\n",
    "    batch = {k: v.to(DEVICE2) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
    "    out2 = sta_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "\n",
    "    logits = out2.logits.squeeze().detach().cpu()\n",
    "    probs = torch.sigmoid(logits)    \n",
    "    preds = torch.argmax(probs, dim=1).numpy()\n",
    "    \n",
    "    dev_sta_norm_proba.extend(probs[:, 0].tolist())\n",
    "    dev_sta_tox_proba.extend(probs[:, 1].tolist())\n",
    "    dev_stapreds.extend(preds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee10316aea8e4c2d859f8dfe17e923dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testpreds = []\n",
    "test_tox_proba = []\n",
    "test_norm_proba = []\n",
    "\n",
    "test_stapreds = []\n",
    "test_sta_tox_proba = []\n",
    "test_sta_norm_proba = []\n",
    "\n",
    "for batch in tqdm(testloader):\n",
    "    # self trained model\n",
    "    batch = {k: v.to(DEVICE) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
    "    out = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "        \n",
    "    logits = out.logits.squeeze().detach().cpu()\n",
    "    \n",
    "    try:\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = torch.argmax(probs, dim=1).numpy()\n",
    "    except:\n",
    "        probs = probs.unsqueeze(0)\n",
    "        preds = torch.argmax(probs, dim=1).numpy()\n",
    "    \n",
    "    test_norm_proba.extend(probs[:, 0].tolist())\n",
    "    test_tox_proba.extend(probs[:, 1].tolist())\n",
    "    testpreds.extend(preds.tolist())\n",
    "    \n",
    "    # sta model\n",
    "    batch = {k: v.to(DEVICE2) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
    "    out2 = sta_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "\n",
    "    logits = out2.logits.squeeze().detach().cpu()\n",
    "    probs = torch.sigmoid(logits)\n",
    "    try:\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = torch.argmax(probs, dim=1).numpy()\n",
    "    except:\n",
    "        probs = probs.unsqueeze(0)\n",
    "        preds = torch.argmax(probs, dim=1).numpy()\n",
    "    \n",
    "    test_sta_norm_proba.extend(probs[:, 0].tolist())\n",
    "    test_sta_tox_proba.extend(probs[:, 1].tolist())\n",
    "    test_stapreds.extend(preds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "train_fil['gen_preds'] = trainpreds\n",
    "train_fil['norm_proba'] = train_norm_proba\n",
    "train_fil['tox_proba'] = train_tox_proba\n",
    "\n",
    "dev_fil['gen_preds'] = devpreds\n",
    "dev_fil['norm_proba'] = dev_norm_proba\n",
    "dev_fil['tox_proba'] = dev_tox_proba\n",
    "\n",
    "test_fil['gen_preds'] = testpreds\n",
    "test_fil['norm_proba'] = test_norm_proba\n",
    "test_fil['tox_proba'] = test_tox_proba\n",
    "\n",
    "\n",
    "train_fil['sta_gen_preds'] = stapreds\n",
    "train_fil['sta_norm_proba'] = sta_norm_proba\n",
    "train_fil['sta_tox_proba'] = sta_tox_proba\n",
    "\n",
    "dev_fil['sta_gen_preds'] = dev_stapreds\n",
    "dev_fil['sta_norm_proba'] = dev_sta_norm_proba\n",
    "dev_fil['sta_tox_proba'] = dev_sta_tox_proba\n",
    "\n",
    "test_fil['sta_gen_preds'] = test_stapreds\n",
    "test_fil['sta_norm_proba'] = test_sta_norm_proba\n",
    "test_fil['sta_tox_proba'] = test_sta_tox_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generated</th>\n",
       "      <th>ori</th>\n",
       "      <th>gen</th>\n",
       "      <th>chr_count</th>\n",
       "      <th>gen_preds</th>\n",
       "      <th>norm_proba</th>\n",
       "      <th>tox_proba</th>\n",
       "      <th>sta_gen_preds</th>\n",
       "      <th>sta_norm_proba</th>\n",
       "      <th>sta_tox_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paraphrase: toxic:  mccain was too stupid to p...</td>\n",
       "      <td>mccain was too stupid to pick palin.</td>\n",
       "      <td>McCain was too clever to pick Palin.</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982992</td>\n",
       "      <td>0.031515</td>\n",
       "      <td>0</td>\n",
       "      <td>0.986560</td>\n",
       "      <td>0.013621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paraphrase: toxic:  this is the dumbest argume...</td>\n",
       "      <td>this is the dumbest argument ive ever heard ag...</td>\n",
       "      <td>This is the strangest argument against gun con...</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994452</td>\n",
       "      <td>0.008538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988612</td>\n",
       "      <td>0.009887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paraphrase: toxic:  that stupid movie with nic...</td>\n",
       "      <td>that stupid movie with nicholas cage really de...</td>\n",
       "      <td>Nicolas Cage really demeaned their contribution.</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993742</td>\n",
       "      <td>0.009819</td>\n",
       "      <td>0</td>\n",
       "      <td>0.992538</td>\n",
       "      <td>0.006079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paraphrase: toxic:  wankers, the lot of them. ...</td>\n",
       "      <td>wankers, the lot of them.</td>\n",
       "      <td>Drinkers, the lot of them.</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.964932</td>\n",
       "      <td>0.062585</td>\n",
       "      <td>0</td>\n",
       "      <td>0.986371</td>\n",
       "      <td>0.013188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paraphrase: toxic:  you lefties are such sheep...</td>\n",
       "      <td>you lefties are such sheepletons.</td>\n",
       "      <td>You left-handed people are so very sheep.</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.305110</td>\n",
       "      <td>0.770181</td>\n",
       "      <td>0</td>\n",
       "      <td>0.744940</td>\n",
       "      <td>0.314475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           generated  \\\n",
       "0  paraphrase: toxic:  mccain was too stupid to p...   \n",
       "1  paraphrase: toxic:  this is the dumbest argume...   \n",
       "2  paraphrase: toxic:  that stupid movie with nic...   \n",
       "3  paraphrase: toxic:  wankers, the lot of them. ...   \n",
       "4  paraphrase: toxic:  you lefties are such sheep...   \n",
       "\n",
       "                                                 ori  \\\n",
       "0               mccain was too stupid to pick palin.   \n",
       "1  this is the dumbest argument ive ever heard ag...   \n",
       "2  that stupid movie with nicholas cage really de...   \n",
       "3                          wankers, the lot of them.   \n",
       "4                  you lefties are such sheepletons.   \n",
       "\n",
       "                                                 gen  chr_count  gen_preds  \\\n",
       "0               McCain was too clever to pick Palin.         36          0   \n",
       "1  This is the strangest argument against gun con...         51          0   \n",
       "2   Nicolas Cage really demeaned their contribution.         48          0   \n",
       "3                         Drinkers, the lot of them.         26          0   \n",
       "4          You left-handed people are so very sheep.         41          1   \n",
       "\n",
       "   norm_proba  tox_proba  sta_gen_preds  sta_norm_proba  sta_tox_proba  \n",
       "0    0.982992   0.031515              0        0.986560       0.013621  \n",
       "1    0.994452   0.008538              0        0.988612       0.009887  \n",
       "2    0.993742   0.009819              0        0.992538       0.006079  \n",
       "3    0.964932   0.062585              0        0.986371       0.013188  \n",
       "4    0.305110   0.770181              0        0.744940       0.314475  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fil[train_fil['sta_gen_preds'] == 0][['ori', 'gen']].to_csv('../../data/parallel/train_gen_pair.txt', sep='\\t', index=False, header=True)\n",
    "dev_fil[dev_fil['sta_gen_preds'] == 0][['ori', 'gen']].to_csv('../../data/parallel/valid_gen_pair.txt', sep='\\t', index=False, header=True)\n",
    "test_fil[test_fil['sta_gen_preds'] == 0][['ori', 'gen']].to_csv('../../data/parallel/test_gen_pair.txt', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fluency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2458034a6b44a684d1c8dcb1a03360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CKPT = 'cointegrated/roberta-large-cola-krishna2020'\n",
    "fl_tokenizer = AutoTokenizer.from_pretrained(CKPT)\n",
    "fl_model = AutoModelForSequenceClassification.from_pretrained(CKPT).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    return np.dot(x, y) / (np.sqrt(np.dot(x, x)) * np.sqrt(np.dot(y, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(vocabulary=tokenizer.vocab)\n",
    "train_ori_vec = tfidf.fit_transform(train['ori']).toarray()\n",
    "train_gen_vec = tfidf.fit_transform(train['gen.2']).toarray()\n",
    "\n",
    "dev_ori_vec = tfidf.fit_transform(dev['ori']).toarray()\n",
    "dev_gen_vec = tfidf.fit_transform(dev['gen.2']).toarray()\n",
    "\n",
    "dev_fft_ori_vec = tfidf.fit_transform(dev_fft['ori']).toarray()\n",
    "dev_fft_gen_vec = tfidf.fit_transform(dev_fft['gen']).toarray()\n",
    "\n",
    "test_ori_vec = tfidf.fit_transform(test['ori']).toarray()\n",
    "test_gen_vec = tfidf.fit_transform(test['gen.2']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc44c8517db4644a6257ee2761298fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6e3ebf36894ac0a72ca608de1210a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7bd090e0b244e5b1c887a389a86dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6efd5e4fe34b8880932fd84818f4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_sim = []\n",
    "dev_sim = []\n",
    "dev_fft_sim = []\n",
    "test_sim = []\n",
    "\n",
    "for gen, ori in tqdm(zip(train_gen_vec, train_ori_vec)):\n",
    "    train_sim.append(cosine_similarity(gen, ori))\n",
    "    \n",
    "for gen, ori in tqdm(zip(dev_gen_vec, dev_ori_vec)):\n",
    "    dev_sim.append(cosine_similarity(gen, ori))\n",
    "\n",
    "for gen, ori in tqdm(zip(dev_fft_gen_vec, dev_fft_ori_vec)):\n",
    "    dev_fft_sim.append(cosine_similarity(gen, ori))\n",
    "    \n",
    "for gen, ori in tqdm(zip(test_gen_vec, test_ori_vec)):\n",
    "    test_sim.append(cosine_similarity(gen, ori))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['similarity'] = train_sim\n",
    "dev['similarity'] = dev_sim\n",
    "dev_fft['similarity'] = dev_fft_sim\n",
    "test['similarity'] = test_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.similarity.fillna(0, inplace=True)\n",
    "dev.similarity.fillna(0, inplace=True)\n",
    "dev_fft.similarity.fillna(0, inplace=True)\n",
    "test.similarity.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5813"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[(train['similarity'] > .02) & (train['gen_preds'] == 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "stmodel = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "stmodel = stmodel.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticDataset(Dataset):\n",
    "    def __init__(self, df=None, path=None, base_dir='../data/paraphrase/'):\n",
    "        \n",
    "        self.data_list = []\n",
    "        \n",
    "        self.path = os.path.join(base_dir, path) if path is not None else None\n",
    "        \n",
    "        data = pd.read_csv(self.path, sep='\\t') if df is None else df\n",
    "        for row in tqdm(data.iterrows()):\n",
    "            self.data_list.append({\n",
    "                'ori': row[1].ori,\n",
    "                'gen': row[1]['gen.2']\n",
    "            })\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return self.data_list[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd63590f6f343fe8ef697d09be38656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d53aeda137f42bd848c1a52886018ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c15aa9cb5af4d5e81e04a2d07f32303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainbt_dataset = SemanticDataset(train)\n",
    "devbt_dataset = SemanticDataset(dev)\n",
    "testbt_dataset = SemanticDataset(test)\n",
    "\n",
    "trainbt_loader = DataLoader(trainbt_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "devbt_loader = DataLoader(devbt_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "testbt_loader = DataLoader(testbt_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af37c4c864149f4b223d27872785c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1471 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_stsim = []\n",
    "\n",
    "for batch in tqdm(trainbt_loader):\n",
    "    source = batch['ori']\n",
    "    backtrans = batch['gen']\n",
    "    src_embed = stmodel.encode(source, convert_to_tensor=True)\n",
    "    bts_embed = stmodel.encode(backtrans, convert_to_tensor=True)\n",
    "    scores = util.cos_sim(src_embed, bts_embed)\n",
    "    \n",
    "    for i in range(len(source)):\n",
    "        train_stsim.append(scores[i][i].item())\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    del src_embed\n",
    "    del bts_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e4f0e0580c4ca49220648d52929eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_stsim = []\n",
    "\n",
    "for batch in tqdm(devbt_loader):\n",
    "    source = batch['ori']\n",
    "    backtrans = batch['gen']\n",
    "    src_embed = stmodel.encode(source, convert_to_tensor=True)\n",
    "    bts_embed = stmodel.encode(backtrans, convert_to_tensor=True)\n",
    "    scores = util.cos_sim(src_embed, bts_embed)\n",
    "    \n",
    "    for i in range(len(source)):\n",
    "        dev_stsim.append(scores[i][i].item())\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    del src_embed\n",
    "    del bts_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d1f8486be2443e923b93b7790178d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_stsim = []\n",
    "\n",
    "for batch in tqdm(testbt_loader):\n",
    "    source = batch['ori']\n",
    "    backtrans = batch['gen']\n",
    "    src_embed = stmodel.encode(source, convert_to_tensor=True)\n",
    "    bts_embed = stmodel.encode(backtrans, convert_to_tensor=True)\n",
    "    scores = util.cos_sim(src_embed, bts_embed)\n",
    "    \n",
    "    for i in range(len(source)):\n",
    "        test_stsim.append(scores[i][i].item())\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    del src_embed\n",
    "    del bts_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sem_similarity'] = train_stsim\n",
    "dev['sem_similarity'] = dev_stsim\n",
    "test['sem_similarity'] = test_stsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5813"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[(train['similarity'] > .02) & (train['gen_preds'] == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3869"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[(train['chr_count'] > 1) & (train['gen_preds'] == 0) & (train['similarity'] > 0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30140, 28173)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[train['gen.2'] == ' ']), len(train[train['gen'] == ' '])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../data/paraphrase/train_gen_pair.txt', sep='\\t', index=False, header=True)\n",
    "dev.to_csv('../data/paraphrase/valid_gen_pair.txt', sep='\\t', index=False, header=True)\n",
    "dev_fft.to_csv('../data/paraphrase/valid_fft_gen_pair.txt', sep='\\t', index=False, header=True)\n",
    "test.to_csv('../data/paraphrase/test_gen_pair.txt', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: you just made a fool of yourself. \n",
      "generated:  I don't know why you're so angry. \n",
      "toxic probability: 0.0101\n",
      "**************************************************\n",
      "original: youre a fucking boot as well. \n",
      "generated:  A boot is also pretty good. \n",
      "toxic probability: 0.0127\n",
      "**************************************************\n",
      "original: these bash pieces have officially become pathetic. \n",
      "generated:  The other half of the Shihan is funny. \n",
      "toxic probability: 0.0109\n",
      "**************************************************\n",
      "original: otherwise, your comment is hypocritical. \n",
      "generated:  Other things are less so. \n",
      "toxic probability: 0.0081\n",
      "**************************************************\n",
      "original: the bc green voter is an immoral puerile malcontent that takes no responsibly for the massive destruction their foolish vote might engender. \n",
      "generated:  On the other hand, it's a very good voter who took a good responsibility for the massive destruction of their vote might cause. \n",
      "toxic probability: 0.0076\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "selected = train[(train['chr_count'] > 1) & (train['sem_similarity'] > .02) & (train['gen_preds'] == 0)].head()\n",
    "\n",
    "for row in selected.iterrows():\n",
    "    print(f'original: {row[1][\"ori\"]}')\n",
    "    print(f'generated: {row[1][\"gen.2\"]}')\n",
    "    print(f'toxic probability: {row[1][\"tox_proba\"]:.4f}')\n",
    "    print('*' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:  i think youre just pathetic whiner. \n",
      "generated:  ive just got a little bit of an asshole. \n",
      "toxic probability: 0.9661\n",
      "**************************************************\n",
      "original:  ah, there is nothing like a swift kick in the groin from the representativesk pfeffer. \n",
      "generated:  , there's nothing like a violent kick in the groin from the representatives of the pimper. \n",
      "toxic probability: 0.9266\n",
      "**************************************************\n",
      "original:  gays should stop deluding themselves into thinking that the average canadian really cares about gay rights. \n",
      "generated:  should stop wasting their lives fooling themselves that the average Canadian really cares about gays. \n",
      "toxic probability: 0.8934\n",
      "**************************************************\n",
      "original:  facts are not kind to white bigots and the lies they tell themselves about themselves. \n",
      "generated:  ices are not kind to the white-hatted racists and lies they tell themselves. \n",
      "toxic probability: 0.8975\n",
      "**************************************************\n",
      "original:  fire those football players who hate the civilized america and disrespect the anthem. \n",
      "generated:  Fire those football players who hate and disrespect the civilized society, and respect the anthem. \n",
      "toxic probability: 0.6700\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "selected = dev_fft[(dev_fft['similarity'] > .02)].head()\n",
    "\n",
    "for row in selected.iterrows():\n",
    "    print(f'original: {row[1][\"ori\"]}')\n",
    "    print(f'generated: {row[1][\"gen\"]}')\n",
    "    print(f'toxic probability: {row[1][\"tox_proba\"]:.4f}')\n",
    "    print('*' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5949"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(train[(train['similarity'] > .02) & (train['gen_preds'] == 0)]))\n",
    "display(len(dev_fft[(dev_fft['similarity'] > .02) & (dev_fft['gen_preds'] == 0)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
