{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Evaluated Backtranslation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruen dataset\n",
    "ruen_train = pd.read_csv('../../data/backtranslation/ruen_train_eval.txt', sep='\\t')\n",
    "ruen_dev = pd.read_csv('../../data/backtranslation/ruen_valid_eval.txt', sep='\\t')\n",
    "ruen_test = pd.read_csv('../../data/backtranslation/ruen_test_eval.txt', sep='\\t')\n",
    "ruen = pd.concat([ruen_train, ruen_dev, ruen_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fren dataset\n",
    "fren_train = pd.read_csv('../../data/backtranslation/fren_train_eval.txt', sep='\\t')\n",
    "fren_dev = pd.read_csv('../../data/backtranslation/fren_valid_eval.txt', sep='\\t')\n",
    "fren_test = pd.read_csv('../../data/backtranslation/fren_test_eval.txt', sep='\\t')\n",
    "fren = pd.concat([fren_train, fren_dev, fren_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esen dataset\n",
    "esen_train = pd.read_csv('../../data/backtranslation/esen_train_eval.txt', sep='\\t')\n",
    "esen_dev = pd.read_csv('../../data/backtranslation/esen_valid_eval.txt', sep='\\t')\n",
    "esen_test = pd.read_csv('../../data/backtranslation/esen_test_eval.txt', sep='\\t')\n",
    "esen = pd.concat([esen_train, esen_dev, esen_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate Similarity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8579955021719157"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fren.sem_similarity.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7984542970358184"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruen.sem_similarity.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8713989429817864"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esen.sem_similarity.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate STA Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = np.zeros(len(ruen), dtype=int)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06864073455320381, 10436)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ground_truth, fren.preds.to_numpy()), len(fren[fren.preds == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06809481840066299, 10353)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ground_truth, ruen.preds.to_numpy()), len(ruen[ruen.preds == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03660926873544772, 5566)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ground_truth, esen.preds.to_numpy()), len(esen[esen.preds == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer on generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load checkpoint\n"
     ]
    }
   ],
   "source": [
    "model = load_checkpoint('../model/ft-robertoxic-classifier.pth', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bt = pd.read_csv('../data/backtranslation/ruen_train.txt', sep='\\t', index_col=0)\n",
    "dev_bt = pd.read_csv('../data/backtranslation/ruen_valid.txt', sep='\\t', index_col=0)\n",
    "test_bt = pd.read_csv('../data/backtranslation/ruen_test.txt', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bt.rename(columns={'translated': 'backtranslate', 'original': 'translate'}, inplace=True)\n",
    "train_bt = train_bt[['source', 'translate', 'backtranslate']]\n",
    "\n",
    "dev_bt.rename(columns={'translated': 'backtranslate', 'original': 'translate'}, inplace=True)\n",
    "dev_bt = dev_bt[['source', 'translate', 'backtranslate']]\n",
    "\n",
    "test_bt.rename(columns={'translated': 'backtranslate', 'original': 'translate'}, inplace=True)\n",
    "test_bt = test_bt[['source', 'translate', 'backtranslate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_toxics = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train_bt[['backtranslate']]),\n",
    "    'validation': Dataset.from_pandas(dev_bt[['backtranslate']]),\n",
    "    'test': Dataset.from_pandas(test_bt[['backtranslate']])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(batch):\n",
    "    comment = batch['backtranslate']\n",
    "    \n",
    "    tokenized = tokenizer(\n",
    "        comment,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        padding='max_length'\n",
    "    )\n",
    "\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaef4e611fa24e29bf3ccfc9a9c8792e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9178bc0d45497eac38cd96fdf66c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592ad9f656fb41b8b55512ebd9526307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['backtranslate', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['backtranslate', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2455\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['backtranslate', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3693\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bt_toxics_tokenized = bt_toxics.map(tokenize_data, batched=True)\n",
    "bt_toxics_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_toxics_tokenized.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainbtloader = DataLoader(bt_toxics_tokenized['train'], shuffle=False, batch_size=BATCH_SIZE)\n",
    "devbtloader = DataLoader(bt_toxics_tokenized['validation'], shuffle=False, batch_size=BATCH_SIZE)\n",
    "testbtloader = DataLoader(bt_toxics_tokenized['test'], shuffle=False, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ca048f68c3463d96a393b76646bf98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainpreds = []\n",
    "\n",
    "for batch in tqdm(trainbtloader):\n",
    "    batch = {k: v.to(DEVICE) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
    "    out = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "    \n",
    "    logits = out.logits.squeeze().detach().cpu()\n",
    "    probs = torch.sigmoid(logits)\n",
    "    preds = torch.argmax(probs, dim=1).numpy()\n",
    "    \n",
    "    \n",
    "    trainpreds.extend(preds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb80d6fa33d4039bea98a6453f75a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "devpreds = []\n",
    "\n",
    "for batch in tqdm(devbtloader):\n",
    "    batch = {k: v.to(DEVICE) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
    "    out = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "    \n",
    "    logits = out.logits.squeeze().detach().cpu()\n",
    "    probs = torch.sigmoid(logits)\n",
    "    preds = torch.argmax(probs, dim=1).numpy()\n",
    "    \n",
    "    devpreds.extend(preds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea2e00d639d430693bccb6a696f5922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testpreds = []\n",
    "\n",
    "for batch in tqdm(testbtloader):\n",
    "    batch = {k: v.to(DEVICE) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
    "    out = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "    \n",
    "    logits = out.logits.squeeze().detach().cpu()\n",
    "    probs = torch.sigmoid(logits)\n",
    "    preds = torch.argmax(probs, dim=1).numpy()\n",
    "    \n",
    "    testpreds.extend(preds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bt['bt_preds'] = trainpreds\n",
    "dev_bt['bt_preds'] = devpreds\n",
    "test_bt['bt_preds'] = testpreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>translate</th>\n",
       "      <th>backtranslate</th>\n",
       "      <th>bt_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>take your admin powers and stick them up your ...</td>\n",
       "      <td>Бери свои административные способности и засун...</td>\n",
       "      <td>Take your administrative skills and shove them...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you just made a fool of yourself .</td>\n",
       "      <td>Ты только что выставил себя дураком.</td>\n",
       "      <td>You just made a fool of yourself.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this animal killer is paying his share .</td>\n",
       "      <td>Этот зверь-убийца платит свою долю.</td>\n",
       "      <td>This killer animal is paying its share.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>so you voted for the loser ?</td>\n",
       "      <td>Значит, вы проголосовали за неудачника?</td>\n",
       "      <td>So you voted for the loser?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>, but we would not expect a bias lib troll lik...</td>\n",
       "      <td>, но мы бы не ожидали, что такой пристрастный ...</td>\n",
       "      <td>but we wouldn't expect a biased troll like you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  take your admin powers and stick them up your ...   \n",
       "1                 you just made a fool of yourself .   \n",
       "2           this animal killer is paying his share .   \n",
       "3                       so you voted for the loser ?   \n",
       "4  , but we would not expect a bias lib troll lik...   \n",
       "\n",
       "                                           translate  \\\n",
       "0  Бери свои административные способности и засун...   \n",
       "1               Ты только что выставил себя дураком.   \n",
       "2                Этот зверь-убийца платит свою долю.   \n",
       "3            Значит, вы проголосовали за неудачника?   \n",
       "4  , но мы бы не ожидали, что такой пристрастный ...   \n",
       "\n",
       "                                       backtranslate  bt_preds  \n",
       "0  Take your administrative skills and shove them...         1  \n",
       "1                  You just made a fool of yourself.         1  \n",
       "2            This killer animal is paying its share.         1  \n",
       "3                        So you voted for the loser?         1  \n",
       "4  but we wouldn't expect a biased troll like you...         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_bt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    return np.dot(x, y) / (np.sqrt(np.dot(x, x)) * np.sqrt(np.dot(y, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:1323: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  \"Upper case characters found in\"\n",
      "/home/jovyan/.local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:1323: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  \"Upper case characters found in\"\n",
      "/home/jovyan/.local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:1323: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  \"Upper case characters found in\"\n",
      "/home/jovyan/.local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:1323: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  \"Upper case characters found in\"\n",
      "/home/jovyan/.local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:1323: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  \"Upper case characters found in\"\n",
      "/home/jovyan/.local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:1323: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  \"Upper case characters found in\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(vocabulary=tokenizer.vocab)\n",
    "train_trans_vec = tfidf.fit_transform(train_bt['backtranslate']).toarray()\n",
    "train_source_vec = tfidf.fit_transform(train_bt['source']).toarray()\n",
    "\n",
    "dev_trans_vec = tfidf.fit_transform(dev_bt['backtranslate']).toarray()\n",
    "dev_source_vec = tfidf.fit_transform(dev_bt['source']).toarray()\n",
    "\n",
    "test_trans_vec = tfidf.fit_transform(test_bt['backtranslate']).toarray()\n",
    "test_source_vec = tfidf.fit_transform(test_bt['source']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae38c6de32644aaa16076b0b625c6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14dd6b1747d34b739681361a5ec14fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676318fea7d342a59e4e9f3970154f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_sim = []\n",
    "dev_sim = []\n",
    "test_sim = []\n",
    "\n",
    "for trans, src in tqdm(zip(train_trans_vec, train_source_vec)):\n",
    "    train_sim.append(cosine_similarity(trans, src))\n",
    "    \n",
    "for trans, src in tqdm(zip(dev_trans_vec, dev_source_vec)):\n",
    "    dev_sim.append(cosine_similarity(trans, src))\n",
    "    \n",
    "for trans, src in tqdm(zip(test_trans_vec, test_source_vec)):\n",
    "    test_sim.append(cosine_similarity(trans, src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bt['similarity'] = train_sim\n",
    "dev_bt['similarity'] = dev_sim\n",
    "test_bt['similarity'] = test_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bt_selected = train_bt[(train_bt.bt_preds == 0) & (train_bt.similarity <= .725)]\n",
    "dev_bt_selected = dev_bt[(dev_bt.bt_preds == 0) & (dev_bt.similarity <= .725)]\n",
    "test_bt_selected = test_bt[(test_bt.bt_preds == 0) & (test_bt.similarity <= .725)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2081 entries, 40 to 3624\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   source         2081 non-null   object \n",
      " 1   translate      2081 non-null   object \n",
      " 2   backtranslate  2081 non-null   object \n",
      " 3   bt_preds       2081 non-null   int64  \n",
      " 4   similarity     2081 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 97.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_paraphrase_ref = pd.concat([train_bt_selected, dev_bt_selected, test_bt_selected])\n",
    "df_paraphrase_ref.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paraphrase_ref.to_csv('../data/paraphrase/paraphrase_ref.csv', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bt.to_csv('../data/paraphrase/train_prep_paraphrase.txt', sep='\\t', index=False, header=True)\n",
    "dev_bt.to_csv('../data/paraphrase/valid_prep_paraphrase.txt', sep='\\t', index=False, header=True)\n",
    "test_bt.to_csv('../data/paraphrase/test_prep_paraphrase.txt', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmodel = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "stmodel = stmodel.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paraphrase_ref = pd.read_csv('../data/paraphrase/paraphrase_ref.csv', sep='\\t')\n",
    "train_bt = pd.read_csv('../data/paraphrase/train_prep_paraphrase.txt', sep='\\t')\n",
    "dev_bt = pd.read_csv('../data/paraphrase/valid_prep_paraphrase.txt', sep='\\t')\n",
    "test_bt = pd.read_csv('../data/paraphrase/test_prep_paraphrase.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticDataset(Dataset):\n",
    "    def __init__(self, path, base_dir='../data/paraphrase/'):\n",
    "        \n",
    "        self.data_list = []\n",
    "        \n",
    "        self.path = os.path.join(base_dir, path)\n",
    "        \n",
    "        data = pd.read_csv(self.path, sep='\\t')\n",
    "        for row in tqdm(data.iterrows()):\n",
    "            self.data_list.append({\n",
    "                'source': row[1].source,\n",
    "                'backtrans': row[1].backtranslate\n",
    "            })\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return self.data_list[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab0638c1133472eb6860088bac7280c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4ed2790d7e40988a2dd79757b81cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a5f55cafce4c58adfc9dcede605009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainbt_dataset = SemanticDataset('train_prep_paraphrase.txt')\n",
    "devbt_dataset = SemanticDataset('valid_prep_paraphrase.txt')\n",
    "testbt_dataset = SemanticDataset('test_prep_paraphrase.txt')\n",
    "\n",
    "trainbt_loader = DataLoader(trainbt_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "devbt_loader = DataLoader(devbt_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "testbt_loader = DataLoader(testbt_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb4d31d8bab4d748dd924956406dcf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_stsim = []\n",
    "\n",
    "for batch in tqdm(trainbt_loader):\n",
    "    source = batch['source']\n",
    "    backtrans = batch['backtrans']\n",
    "    src_embed = stmodel.encode(source, convert_to_tensor=True)\n",
    "    bts_embed = stmodel.encode(backtrans, convert_to_tensor=True)\n",
    "    scores = util.cos_sim(src_embed, bts_embed)\n",
    "    \n",
    "    for i in range(len(source)):\n",
    "        train_stsim.append(scores[i][i].item())\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    del src_embed\n",
    "    del bts_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741fcce9d70a40e7b180dc357f4fa8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_stsim = []\n",
    "\n",
    "for batch in tqdm(devbt_loader):\n",
    "    source = batch['source']\n",
    "    backtrans = batch['backtrans']\n",
    "    src_embed = stmodel.encode(source, convert_to_tensor=True)\n",
    "    bts_embed = stmodel.encode(backtrans, convert_to_tensor=True)\n",
    "    scores = util.cos_sim(src_embed, bts_embed)\n",
    "    \n",
    "    for i in range(len(source)):\n",
    "        dev_stsim.append(scores[i][i].item())\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    del src_embed\n",
    "    del bts_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e312a9270024cf48c53d81236e2189b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_stsim = []\n",
    "\n",
    "for batch in tqdm(testbt_loader):\n",
    "    source = batch['source']\n",
    "    backtrans = batch['backtrans']\n",
    "    src_embed = stmodel.encode(source, convert_to_tensor=True)\n",
    "    bts_embed = stmodel.encode(backtrans, convert_to_tensor=True)\n",
    "    scores = util.cos_sim(src_embed, bts_embed)\n",
    "    \n",
    "    for i in range(len(source)):\n",
    "        test_stsim.append(scores[i][i].item())\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    del src_embed\n",
    "    del bts_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bt['sem_similarity'] = train_stsim\n",
    "dev_bt['sem_similarity'] = dev_stsim\n",
    "test_bt['sem_similarity'] = test_stsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>translate</th>\n",
       "      <th>backtranslate</th>\n",
       "      <th>bt_preds</th>\n",
       "      <th>similarity</th>\n",
       "      <th>sem_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>take your admin powers and stick them up your ...</td>\n",
       "      <td>Бери свои административные способности и засун...</td>\n",
       "      <td>Take your administrative skills and shove them...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.654044</td>\n",
       "      <td>0.797628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you just made a fool of yourself .</td>\n",
       "      <td>Ты только что выставил себя дураком.</td>\n",
       "      <td>You just made a fool of yourself.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999817</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this animal killer is paying his share .</td>\n",
       "      <td>Этот зверь-убийца платит свою долю.</td>\n",
       "      <td>This killer animal is paying its share.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.903200</td>\n",
       "      <td>0.950419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>so you voted for the loser ?</td>\n",
       "      <td>Значит, вы проголосовали за неудачника?</td>\n",
       "      <td>So you voted for the loser?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999822</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>, but we would not expect a bias lib troll lik...</td>\n",
       "      <td>, но мы бы не ожидали, что такой пристрастный ...</td>\n",
       "      <td>but we wouldn't expect a biased troll like you...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.425269</td>\n",
       "      <td>0.828127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  take your admin powers and stick them up your ...   \n",
       "1                 you just made a fool of yourself .   \n",
       "2           this animal killer is paying his share .   \n",
       "3                       so you voted for the loser ?   \n",
       "4  , but we would not expect a bias lib troll lik...   \n",
       "\n",
       "                                           translate  \\\n",
       "0  Бери свои административные способности и засун...   \n",
       "1               Ты только что выставил себя дураком.   \n",
       "2                Этот зверь-убийца платит свою долю.   \n",
       "3            Значит, вы проголосовали за неудачника?   \n",
       "4  , но мы бы не ожидали, что такой пристрастный ...   \n",
       "\n",
       "                                       backtranslate  bt_preds  similarity  \\\n",
       "0  Take your administrative skills and shove them...         1    0.654044   \n",
       "1                  You just made a fool of yourself.         1    0.999817   \n",
       "2            This killer animal is paying its share.         1    0.903200   \n",
       "3                        So you voted for the loser?         1    0.999822   \n",
       "4  but we wouldn't expect a biased troll like you...         1    0.425269   \n",
       "\n",
       "   sem_similarity  \n",
       "0        0.797628  \n",
       "1        1.000000  \n",
       "2        0.950419  \n",
       "3        1.000000  \n",
       "4        0.828127  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_bt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bt_selected = train_bt[(train_bt.bt_preds == 0) & (train_bt.sem_similarity < 0.48)]\n",
    "dev_bt_selected = dev_bt[(dev_bt.bt_preds == 0)]\n",
    "test_bt_selected = test_bt[(test_bt.bt_preds == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3233 entries, 6 to 3624\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   source          3233 non-null   object \n",
      " 1   translate       3233 non-null   object \n",
      " 2   backtranslate   3233 non-null   object \n",
      " 3   bt_preds        3233 non-null   int64  \n",
      " 4   similarity      3206 non-null   float64\n",
      " 5   sem_similarity  3233 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 176.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_paraphrase_ref = pd.concat([train_bt_selected, dev_bt_selected, test_bt_selected])\n",
    "df_paraphrase_ref.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>translate</th>\n",
       "      <th>backtranslate</th>\n",
       "      <th>bt_preds</th>\n",
       "      <th>similarity</th>\n",
       "      <th>sem_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>obama has defecated on israel repeatedly .</td>\n",
       "      <td>Обама неоднократно обезвоживала Израэля.</td>\n",
       "      <td>Obama dehydrated Israel repeatedly.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>bla bla bla you can spin yourself stupid all y...</td>\n",
       "      <td>Бла-бла-бла, ты можешь крутить себя глупо, ско...</td>\n",
       "      <td>Blah, blah, blah, blah, blah, blah, blah, blah...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.244442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>waah screams the butthurt commie loser !</td>\n",
       "      <td>Ваа кричит задница, музыка-неудачник!</td>\n",
       "      <td>Whoa, whoa, whoa, whoa, whoa, whoa, whoa, whoa...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.228463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>ive had it up to here with idiots who want poo...</td>\n",
       "      <td>.................................................</td>\n",
       "      <td>.................................................</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6501</th>\n",
       "      <td>paul martin , stephen harper , brian mulroney ...</td>\n",
       "      <td>Пол Мартин, Стефен Харпер, Брайан Мулрони (он ...</td>\n",
       "      <td>Paul Martin, Stephen Harper, Brian Mulroni.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6745</th>\n",
       "      <td>muslim ban rejected by DIGIT ororfederal court...</td>\n",
       "      <td>)................................................</td>\n",
       "      <td>(i.e. )</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.066378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8084</th>\n",
       "      <td>recycled , retread , useless lifers .</td>\n",
       "      <td>Рециркуляция, восстановление протектора, беспо...</td>\n",
       "      <td>Recirculation, retreading, useless life-saving...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10520</th>\n",
       "      <td>slang a man who is unpleasant or not to be tru...</td>\n",
       "      <td>:................................................</td>\n",
       "      <td>:...............................</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.097186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11426</th>\n",
       "      <td>ulysses simpson grant , the drunkard !</td>\n",
       "      <td>Улисс Симпсон Грант, пьяница!</td>\n",
       "      <td>Ulysses Simpson Grant, drunk!</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11873</th>\n",
       "      <td>i dont refute unhinged blather .</td>\n",
       "      <td>Я не опровергаю бессердечный блейтер.</td>\n",
       "      <td>I'm not denying a heartless blather.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.646244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16273</th>\n",
       "      <td>i recommend the firing squad .</td>\n",
       "      <td>Я рекомендую расстрел.</td>\n",
       "      <td>I recommend a shotgun.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.568303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17563</th>\n",
       "      <td>a truly unfit traitorous vacuous buffoon .</td>\n",
       "      <td>По-настоящему неподходящее предательское безде...</td>\n",
       "      <td>It's a really bad treachery.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.193665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19603</th>\n",
       "      <td>sjws dont care about middleaged white males ki...</td>\n",
       "      <td>:................................................</td>\n",
       "      <td>::...............................................</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21331</th>\n",
       "      <td>hehehehehehehehehehheheheehehehehehehehehehehe...</td>\n",
       "      <td>Эхехехехехехехехехехехехехехехехехехехехехехех...</td>\n",
       "      <td>Eheheheheheheheheheheheheheheheheheheheheheheh...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.222502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21524</th>\n",
       "      <td>waah says the commie troll !</td>\n",
       "      <td>Ваа говорит, что тролль коммии!</td>\n",
       "      <td>Whoa, whoa, whoa, whoa, whoa, whoa, whoa, whoa...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.168467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22544</th>\n",
       "      <td>wow you ppl are fucked up .</td>\n",
       "      <td>Ух ты, ты, пиздец, пиздец.</td>\n",
       "      <td>Whoa, whoa, whoa, whoa, whoa, whoa.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.072579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24116</th>\n",
       "      <td>( reinsert thumb , suck ) )</td>\n",
       "      <td>(Вставить большой палец, отсос)</td>\n",
       "      <td>(Add thumb, suction)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.646852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33854</th>\n",
       "      <td>frozen sucksvfrozen sucksfrozen sucksfrozen su...</td>\n",
       "      <td>замороженный отсос замороженный отсос замороже...</td>\n",
       "      <td>Frozen suction, frozen suction, frozen suction...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.401727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36449</th>\n",
       "      <td>lol u r prolly an orc to .</td>\n",
       "      <td>lol u rolly orc to.</td>\n",
       "      <td>:: :: ::.........................................</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.228463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36795</th>\n",
       "      <td>agreed , this article is a complete heap of ru...</td>\n",
       "      <td>,,,,,,,..........................................</td>\n",
       "      <td>,,,,,,,,,,....................................</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.089427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40065</th>\n",
       "      <td>waah said the commie troll !</td>\n",
       "      <td>Вааа сказал, что тролль коммии!</td>\n",
       "      <td>Whoa, whoa, whoa, whoa, whoa, whoa, whoa, whoa...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.151068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42965</th>\n",
       "      <td>frozen sucksfrozen sucksfrozen sucksfrozen suc...</td>\n",
       "      <td>замороженный отсос замороженный отстой заморож...</td>\n",
       "      <td>Frozen suction, frozen muck, frozen muck.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.460727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45749</th>\n",
       "      <td>ahh , crony cap oily thugs .</td>\n",
       "      <td>аххххххххххххххххххххххммммммммммхммммхммммхмм...</td>\n",
       "      <td>Ahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>trump as putins lapdog : .</td>\n",
       "      <td>:................................................</td>\n",
       "      <td>::...............................................</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>the donaldson bunt , ridiculous .</td>\n",
       "      <td>Дональдсонский койчок, смешной.</td>\n",
       "      <td>Donaldson bunk, funny.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.702250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>blah blah blah fck you .</td>\n",
       "      <td>Бла-бла-бла-бла-бла-бла-бла-бла-бла-бла-бла-бл...</td>\n",
       "      <td>Blah, blah, blah, blah, blah, blah, blah, blah...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.418862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3472</th>\n",
       "      <td>: : : : fuck .</td>\n",
       "      <td>:: : : : : : : : : : : :.........................</td>\n",
       "      <td>:: :: :: :: ::...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.474578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  source  \\\n",
       "633           obama has defecated on israel repeatedly .   \n",
       "830    bla bla bla you can spin yourself stupid all y...   \n",
       "1216            waah screams the butthurt commie loser !   \n",
       "1744   ive had it up to here with idiots who want poo...   \n",
       "6501   paul martin , stephen harper , brian mulroney ...   \n",
       "6745   muslim ban rejected by DIGIT ororfederal court...   \n",
       "8084               recycled , retread , useless lifers .   \n",
       "10520  slang a man who is unpleasant or not to be tru...   \n",
       "11426             ulysses simpson grant , the drunkard !   \n",
       "11873                   i dont refute unhinged blather .   \n",
       "16273                     i recommend the firing squad .   \n",
       "17563         a truly unfit traitorous vacuous buffoon .   \n",
       "19603  sjws dont care about middleaged white males ki...   \n",
       "21331  hehehehehehehehehehheheheehehehehehehehehehehe...   \n",
       "21524                       waah says the commie troll !   \n",
       "22544                        wow you ppl are fucked up .   \n",
       "24116                        ( reinsert thumb , suck ) )   \n",
       "33854  frozen sucksvfrozen sucksfrozen sucksfrozen su...   \n",
       "36449                         lol u r prolly an orc to .   \n",
       "36795  agreed , this article is a complete heap of ru...   \n",
       "40065                       waah said the commie troll !   \n",
       "42965  frozen sucksfrozen sucksfrozen sucksfrozen suc...   \n",
       "45749                       ahh , crony cap oily thugs .   \n",
       "2388                          trump as putins lapdog : .   \n",
       "484                    the donaldson bunt , ridiculous .   \n",
       "2009                            blah blah blah fck you .   \n",
       "3472                                      : : : : fuck .   \n",
       "\n",
       "                                               translate  \\\n",
       "633             Обама неоднократно обезвоживала Израэля.   \n",
       "830    Бла-бла-бла, ты можешь крутить себя глупо, ско...   \n",
       "1216               Ваа кричит задница, музыка-неудачник!   \n",
       "1744   .................................................   \n",
       "6501   Пол Мартин, Стефен Харпер, Брайан Мулрони (он ...   \n",
       "6745   )................................................   \n",
       "8084   Рециркуляция, восстановление протектора, беспо...   \n",
       "10520  :................................................   \n",
       "11426                      Улисс Симпсон Грант, пьяница!   \n",
       "11873              Я не опровергаю бессердечный блейтер.   \n",
       "16273                             Я рекомендую расстрел.   \n",
       "17563  По-настоящему неподходящее предательское безде...   \n",
       "19603  :................................................   \n",
       "21331  Эхехехехехехехехехехехехехехехехехехехехехехех...   \n",
       "21524                    Ваа говорит, что тролль коммии!   \n",
       "22544                         Ух ты, ты, пиздец, пиздец.   \n",
       "24116                    (Вставить большой палец, отсос)   \n",
       "33854  замороженный отсос замороженный отсос замороже...   \n",
       "36449                                lol u rolly orc to.   \n",
       "36795  ,,,,,,,..........................................   \n",
       "40065                    Вааа сказал, что тролль коммии!   \n",
       "42965  замороженный отсос замороженный отстой заморож...   \n",
       "45749  аххххххххххххххххххххххммммммммммхммммхммммхмм...   \n",
       "2388   :................................................   \n",
       "484                      Дональдсонский койчок, смешной.   \n",
       "2009   Бла-бла-бла-бла-бла-бла-бла-бла-бла-бла-бла-бл...   \n",
       "3472   :: : : : : : : : : : : :.........................   \n",
       "\n",
       "                                           backtranslate  bt_preds  \\\n",
       "633                  Obama dehydrated Israel repeatedly.         0   \n",
       "830    Blah, blah, blah, blah, blah, blah, blah, blah...         0   \n",
       "1216   Whoa, whoa, whoa, whoa, whoa, whoa, whoa, whoa...         0   \n",
       "1744   .................................................         0   \n",
       "6501         Paul Martin, Stephen Harper, Brian Mulroni.         0   \n",
       "6745                                             (i.e. )         0   \n",
       "8084   Recirculation, retreading, useless life-saving...         0   \n",
       "10520                   :...............................         0   \n",
       "11426                      Ulysses Simpson Grant, drunk!         0   \n",
       "11873               I'm not denying a heartless blather.         0   \n",
       "16273                             I recommend a shotgun.         0   \n",
       "17563                       It's a really bad treachery.         0   \n",
       "19603  ::...............................................         0   \n",
       "21331  Eheheheheheheheheheheheheheheheheheheheheheheh...         0   \n",
       "21524  Whoa, whoa, whoa, whoa, whoa, whoa, whoa, whoa...         0   \n",
       "22544                Whoa, whoa, whoa, whoa, whoa, whoa.         0   \n",
       "24116                               (Add thumb, suction)         0   \n",
       "33854  Frozen suction, frozen suction, frozen suction...         0   \n",
       "36449  :: :: ::.........................................         0   \n",
       "36795     ,,,,,,,,,,....................................         0   \n",
       "40065  Whoa, whoa, whoa, whoa, whoa, whoa, whoa, whoa...         0   \n",
       "42965          Frozen suction, frozen muck, frozen muck.         0   \n",
       "45749  Ahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...         0   \n",
       "2388   ::...............................................         0   \n",
       "484                               Donaldson bunk, funny.         0   \n",
       "2009   Blah, blah, blah, blah, blah, blah, blah, blah...         0   \n",
       "3472                                   :: :: :: :: ::...         0   \n",
       "\n",
       "       similarity  sem_similarity  \n",
       "633           NaN        0.716210  \n",
       "830           NaN        0.244442  \n",
       "1216          NaN        0.228463  \n",
       "1744          NaN        0.138859  \n",
       "6501          NaN        0.813203  \n",
       "6745          NaN        0.066378  \n",
       "8084          NaN        0.617553  \n",
       "10520         NaN        0.097186  \n",
       "11426         NaN        0.933305  \n",
       "11873         NaN        0.646244  \n",
       "16273         NaN        0.568303  \n",
       "17563         NaN        0.193665  \n",
       "19603         NaN        0.049640  \n",
       "21331         NaN        0.222502  \n",
       "21524         NaN        0.168467  \n",
       "22544         NaN        0.072579  \n",
       "24116         NaN        0.646852  \n",
       "33854         NaN        0.401727  \n",
       "36449         NaN        0.228463  \n",
       "36795         NaN        0.089427  \n",
       "40065         NaN        0.151068  \n",
       "42965         NaN        0.460727  \n",
       "45749         NaN        0.083873  \n",
       "2388          NaN        0.096918  \n",
       "484           NaN        0.702250  \n",
       "2009          NaN        0.418862  \n",
       "3472          NaN        0.474578  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_paraphrase_ref[df_paraphrase_ref['similarity'].isnull()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
